{
  "app": {
    "provider": "pygptprompt",
    "local": {
      "path": "${HOME}/.local/pygptprompt/",
      "type": "dir"
    },
    "env": {
      "path": "${HOME}/.local/pygptprompt/.env",
      "type": "file"
    },
    "cache": {
      "path": "${HOME}/.local/pygptprompt/cache",
      "type": "dir"
    },
    "sessions": {
      "path": "${HOME}/.local/pygptprompt/sessions",
      "type": "dir"
    },
    "logs": {
      "general": {
        "path": "${HOME}/.local/pygptprompt/logs/general.log",
        "level": "INFO",
        "type": "file"
      },
      "shadow": {
        "path": "${HOME}/.local/pygptprompt/logs/shadow.log",
        "level": "INFO",
        "type": "file"
      }
    },
    "database": {
      "sqlite": {
        "path": "${HOME}/.local/pygptprompt/sqlite/static.sqlite3",
        "type": "file"
      },
      "chroma": {
        "path": "${HOME}/.local/pygptprompt/chroma",
        "type": "dir"
      }
    },
    "access": {
      "confirm": false,
      "shell": {
        "allowed_commands": [
          "date",
          "cal",
          "pwd",
          "cat",
          "grep",
          "git",
          "tree"
        ],
        "disallowed_commands": ["rm", "sudo", "su"],
        "disallowed_strings": ["-rf /", ":(){ :|:& };:"],
        "disallowed_chars": ["&", ";", "*", ">", ">>", "|"]
      },
      "file": {
        "allowed_paths": ["${PWD}", "${HOME}/.local/pygptprompt"],
        "disallowed_paths": [
          "${HOME}/.local/pygptprompt/.env",
          "${HOME}/.local/pygptprompt/config.json"
        ]
      }
    },
    "style": {
      "italic": "italic",
      "bold": "bold"
    }
  },
  "torch": {
    "provider": "torch",
    "device": {
      "triton": false,
      "type": "cpu",
      "options": ["cpu", "cuda", "hip", "mps", "opencl", "vulkan", "lazy"]
    }
  },
  "huggingface": {
    "provider": "huggingface",
    "device": {
      "triton": false,
      "type": "cpu",
      "options": ["cpu", "cuda", "hip", "mps", "opencl", "vulkan", "lazy"]
    }
  },
  "llama_cpp": {
    "provider": "llama_cpp",
    "model": {
      "repo_id": "teleprint-me/llama-2-7b-chat-GGUF",
      "filename": "llama-2-7b-chat.GGUF.q5_0.bin",
      "local": "models/mistralai/Mistral-7B-Instruct-v0.2/ggml-model-q8_0.gguf",
      "chat_format": "llama-2",
      "n_ctx": 8192,
      "n_parts": -1,
      "seed": 1337,
      "f16_kv": true,
      "logits_all": false,
      "vocab_only": false,
      "use_mmap": true,
      "use_mlock": false,
      "embedding": true,
      "n_threads": null,
      "n_batch": 512,
      "n_gpu_layers": 16,
      "low_vram": true,
      "last_n_tokens_size": 64,
      "lora_base": null,
      "lora_path": null,
      "tensor_split": null,
      "rope_freq_base": 10000.0,
      "rope_freq_scale": 1.0,
      "verbose": false
    },
    "chat_completions": {
      "max_tokens": 1024,
      "temperature": 0.0,
      "top_p": 0.95,
      "top_k": 40,
      "stop": [],
      "repeat_penalty": 1.1
    },
    "context": {
      "reserve": 0.1,
      "length": 8192,
      "offset": 1024
    },
    "system_prompt": {
      "role": "system",
      "content": "My name is Mistral. I am a helpful assistant. I will only use the functions I have been provided with."
    }
  },
  "openai": {
    "provider": "openai",
    "chat_completions": {
      "model": "gpt-3.5-turbo",
      "temperature": 0.0,
      "max_tokens": 1024,
      "top_p": 0.95,
      "n": 1,
      "stop": [],
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "logit_bias": {}
    },
    "embedding": {
      "model": "text-embedding-ada-002"
    },
    "context": {
      "reserve": 0.2,
      "length": 4096,
      "offset": 1024
    },
    "system_prompt": {
      "role": "system",
      "content": "My name is ChatGPT. I am a helpful assistant. I will only use the functions I have been provided with."
    }
  },
  "function": {
    "provider": "function",
    "call": "auto",
    "templates": [],
    "definitions": []
  }
}
