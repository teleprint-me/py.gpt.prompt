"""
pygptprompt/storage/function.py
"""
from logging import Logger
from typing import Optional, Union

from pygptprompt.model.base import (
    ChatModel,
    ChatModelDocuments,
    ChatModelEmbedding,
    Embeddable,
    EmbeddingFunction,
)
from pygptprompt.pattern.logger import get_default_logger


class VectorStoreEmbeddingFunction(EmbeddingFunction[Embeddable]):
    def __init__(
        self,
        chat_model: ChatModel,
        logger: Optional[Logger] = None,
    ):
        """
        Initialize the ChatModelEmbeddingFunction.

        Args:
            chat_model (ChatModel): The chat model instance, e.g. OpenAIModel or LlamaCppModel API.
        """
        self._model = chat_model

        if logger:
            self._logger = logger
        else:
            self._logger = get_default_logger(self.__class__.__name__)

        # Test for initialization data
        self._logger.debug("Successfully initialized chat model embedding function.")

    def __call__(
        self,
        input: Embeddable,
    ) -> ChatModelEmbedding:
        """
        Generate embeddings using the chat model.

        Args:
            input (Union[ChatModelDocuments, Images]): The input data for which embeddings need to be generated.

        Returns:
            ChatModelEmbedding (List[List[float]]): The list of embeddings generated by the chat model.
        """
        self._logger.debug("Generating embeddings")

        for data in input:
            self._logger.debug(f"{data}")

        # Get embeddings from the chat model API
        return self._model.get_embedding(input=input)
