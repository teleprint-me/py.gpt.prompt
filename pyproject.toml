#
# NOTE: SciPy Vulnerability
# The Python version must be constrained in order to resolve this issue.
#
# NOTE: Resolve PyTorch dependency
# This is the most satisfying solution for now and will default to CPU as a result.
# poetry source add -p explicit pytorch https://download.pytorch.org/whl/cpu
# poetry add --source pytorch torch torchvision
#
# NOTE: Missing Shared Objects with PyTorch
# Use `pip install torch` to resolve platform specific issues.
# The missing shared objects will be installed as a result.
# https://stackoverflow.com/questions/59158044/poetry-and-pytorch
# https://github.com/python-poetry/poetry/issues/2247
# https://pytorch.org/get-started/locally/
#
# NOTE: PyTorch Workaround is to manually install using pip
# CPU:
# pip3 install torch --index-url https://download.pytorch.org/whl/cpu
#
# ROCm:
# pip3 install torch --index-url https://download.pytorch.org/whl/rocm5.4.2
#
# Nvidia: CUDA wheel is default:
# pip3 install torch
#
[tool.poetry]
name = "pygptprompt"
version = "0.0.43"
description = "PyGPTPrompt: A Context Window Management System for Automating Prompting with Chat Models."
authors = ["Austin Berrio <aberrio@teleprint.me>"]
license = "AGPL"
readme = "README.md"
keywords = ["openai", "gpt", "llama", "llama.cpp", "python", "prompt", "automation", "api"]

[tool.poetry.dependencies]
python = ">=3.11"

# Core Libraries
numpy = "^1.26.4"

# Web and Data Retrieval
requests = "^2.31.0"
beautifulsoup4 = "^4.12.3"
feedparser = "^6.0.11"
html2text = "^2024.2.26"
python-poppler = "^0.4.1"

# Command-line Tools
click = "^8.1.7"
python-dotenv = "^1.0.1"
python-magic = "^0.4.27"
prompt-toolkit = "^3.0.43"
rich = "^13.7.1"
inquirer = "^3.2.4"
tqdm = "^4.66.4"
pyperclip = "^1.8.2"

# Web Automation and Image Processing
selenium = "^4.20.0"
opencv-python = "^4.9.0.80"
pytesseract = "^0.3.10"

# Database and ORM
peewee = "^3.17.5"
chromadb = "^0.5.0"

# PyTorch and Extensions
torch = {version = "^2.3.0+cpu", source = "pytorch"}
fairscale = "^0.4.13"

# NLP (Natural Language Processing)
huggingface-hub = "^0.23.0"
transformers = "^4.40.2"
safetensors = "^0.4.3"
sentencepiece = "^0.2.0"
peft = "^0.10.0"

# Byte Pair Encoding (BPE) for NLP
tiktoken = "^0.6.0"

# AI Models and Embeddings
openai = {extras = ["embeddings"], version = "^1.28.2"}

# Llama.cpp and Frontend
# planned deprecation: llama-cpp-python will be completely removed in the future
# llama-cpp-python will be superceded by the llama.cpp server for the interim
# custom support will be implemented gradually over time favoring a completions api.
llama-cpp-python = "^0.2.74"
diffusers = "^0.27.2"

[tool.poetry.dev-dependencies]
bpython = "^0.24"
pre_commit = "^3.7.1"
pyupgrade = "^3.15.2"
pytest = "^8.2.0"
black = "^24.4.2"
isort = "^5.13.2"
flake8 = "^7.0.0"
build = "^1.2.1"
mkdocs = "^1.6.0"
mkdocstrings = {version = "^0.25.1", extras = ["python"]}
mkdocs-material = "^9.5.22"
ipykernel = "^6.29.4"  # Required for VSCode
# jupyter = "^1.0.0"  # Install if needed
# pynvim = "^0.4.3"  # Install if needed

[[tool.poetry.source]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[tool.pytest.ini_options]
markers = [
    "slow: run slow tests",
    "private: test private endpoints",
]

[tool.build]
packages = [
  { include = "pygptprompt" }
]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
