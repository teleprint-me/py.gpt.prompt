#
# NOTE: SciPy Vulnerability
# The Python version must be constrained in order to resolve this issue.
#
# NOTE: Resolve PyTorch dependency
# This is the most satisfying solution for now and will default to CPU as a result.
# poetry source add -p explicit pytorch https://download.pytorch.org/whl/cpu
# poetry add --source pytorch torch torchvision
#
# NOTE: Missing Shared Objects with PyTorch
# Use `pip install torch` to resolve platform specific issues.
# The missing shared objects will be installed as a result.
# https://stackoverflow.com/questions/59158044/poetry-and-pytorch
# https://github.com/python-poetry/poetry/issues/2247
# https://pytorch.org/get-started/locally/
#
# NOTE: PyTorch Workaround is to manually install using pip
# CPU:
# pip3 install torch --index-url https://download.pytorch.org/whl/cpu
#
# ROCm:
# pip3 install torch --index-url https://download.pytorch.org/whl/rocm5.4.2
#
# Nvidia: CUDA wheel is default:
# pip3 install torch
#
[tool.poetry]
name = "pygptprompt"
version = "0.0.41"
description = "PyGPTPrompt: A Context Window Management System for Automating Prompting with Chat Models."
authors = ["Austin Berrio <aberrio@teleprint.me>"]
license = "AGPL"
readme = "README.md"
keywords = ["openai", "gpt", "llama", "llama.cpp", "python", "prompt", "automation", "api"]

[tool.poetry.dependencies]
python = ">=3.11,<3.12"

# Core Libraries
numpy = "^1.26.2"

# Web and Data Retrieval
requests = "^2.31.0"
beautifulsoup4 = "^4.12.2"
feedparser = "^6.0.10"
html2text = "^2020.1.16"

# Command-line Tools
click = "^8.1.7"
python-dotenv = "^1.0.0"
python-magic = "^0.4.27"
prompt-toolkit = "^3.0.43"
rich = "^13.7.0"
inquirer = "^3.1.4"

# Web Automation and Image Processing
selenium = "^4.16.0"
opencv-python = "^4.8.1.78"
pytesseract = "^0.3.10"

# Database and ORM
peewee = "^3.17.0"
chromadb = "^0.4.19"

# PyTorch and Extensions
torch = {version = "^2.1.2+cpu", source = "pytorch"}
fairscale = "^0.4.13"

# NLP (Natural Language Processing)
transformers = "^4.36.2"
safetensors = "^0.4.1"
sentencepiece = "^0.1.99"

# Byte Pair Encoding (BPE) for NLP
tiktoken = "^0.5.2"

# AI Models and Embeddings
openai = {extras = ["embeddings"], version = "^1.5.0"}

# Llama.cpp and Frontend
llama-cpp-python = "^0.2.23"
gguf = "^0.6.0"

[tool.poetry.dev-dependencies]
bpython = "^0.24"
pre_commit = "^3.6.0"
pyupgrade = "^3.15.0"
pytest = "^7.4.3"
black = "^23.12.0"
isort = "^5.13.2"
flake8 = "^6.1.0"
build = "^1.0.3"
mkdocs = "^1.5.3"
mkdocstrings = {version = "^0.24.0", extras = ["python"]}
mkdocs-material = "^9.4.10"
ipykernel = "^6.27.0"  # Required for VSCode
# jupyter = "^1.0.0"  # Install if needed
# pynvim = "^0.4.3"  # Install if needed

[[tool.poetry.source]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[tool.pytest.ini_options]
markers = [
    "slow: run slow tests",
    "private: test private endpoints",
]

[tool.build]
packages = [
  { include = "pygptprompt" }
]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
